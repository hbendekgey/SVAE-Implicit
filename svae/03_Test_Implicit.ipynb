{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c223035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jax import vmap, grad, random, jit, tree_map\n",
    "import jax.numpy as jnp\n",
    "from inference.MP_Inference import lds_inference, lds_inference_sequential, lds_inference_homog, hmm_inference, lds_to_hmm_mf, hmm_to_lds_mf\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from inference import SLDS_Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6758134",
   "metadata": {},
   "source": [
    "This notebook assumes `slds.pkl` has been constructed by the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d94ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved_models/slds.pkl\", 'rb') as f:\n",
    "    recog_potentials, pgm_potentials, _, _ = pickle.load(f)\n",
    "\n",
    "all_params = (recog_potentials, *pgm_potentials)\n",
    "\n",
    "initializer = random.PRNGKey(47)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564df3de",
   "metadata": {},
   "source": [
    "In this notebook, we will set the convergence threshold used to prematurely end iterative inference to 0, thus guaranteeing we take the specified number of inference steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd29d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLDS_Inference.CONV_THRESH = 0.\n",
    "_, cat_expected_stats1 = SLDS_Inference.slds_inference_unrolled(*all_params, initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d1ca7c",
   "metadata": {},
   "source": [
    "Once a function gets compiled by jit, changing a global variable won't change the inner workings of the function. If we want to try running it with different global variable setting, we have to reload (obviously in an ideal world, this parameter would be an argument, but this made less sense for model training than it does here for debugging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d07606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(SLDS_Inference)\n",
    "SLDS_Inference.MAX_ITER = 20\n",
    "SLDS_Inference.CONV_THRESH = 0.\n",
    "\n",
    "_, cat_expected_stats2 = SLDS_Inference.slds_inference_unrolled(*all_params, initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575f69d5",
   "metadata": {},
   "source": [
    "The endpoint of optimization is slightly different after 10 vs 20 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e76203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.00154468, dtype=float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.abs(cat_expected_stats2 - cat_expected_stats1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ab09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(SLDS_Inference)\n",
    "SLDS_Inference.MAX_ITER = 50\n",
    "SLDS_Inference.CONV_THRESH = 0.\n",
    "\n",
    "_, cat_expected_stats3 = SLDS_Inference.slds_inference_unrolled(*all_params, initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d299f",
   "metadata": {},
   "source": [
    "After 20 iterations, it's a lot closer to converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d44d04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.00010522, dtype=float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.abs(cat_expected_stats3 - cat_expected_stats2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d67776",
   "metadata": {},
   "source": [
    "Now let's check to make sure the implicit function gives the same (forward pass) output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa7a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaus_expected_stats, cat_expected_stats = SLDS_Inference.slds_inference_implicit(*all_params, initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e70d3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(7.3085262e-15, dtype=float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean(jnp.abs(cat_expected_stats - cat_expected_stats3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9a746",
   "metadata": {},
   "source": [
    "Almost exactly the same! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a1578b",
   "metadata": {},
   "source": [
    "#### Gradient check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b835c552",
   "metadata": {},
   "source": [
    "Now, let's start comparing the gradients computed by the two methods. \n",
    "\n",
    "This example is so small (a single sequence with length $T=100$ and dimension $d=5$ that unrolled gradients work fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0c07952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2483.4785798474977\n"
     ]
    }
   ],
   "source": [
    "# start by defining some arbitrary scalar-valued function of the output, so we can backprop\n",
    "def composition_func(params):\n",
    "    a,b,_ = SLDS_Inference.slds_inference_unrolled_baseline(*params, initializer)\n",
    "    \n",
    "    # computes KL(q(z,k) || p(z,k))\n",
    "    c = SLDS_Inference.slds_kl(*params, a, b, 0.) \n",
    "    return sum(tree_map(lambda x: x.sum(), a)) + c\n",
    "\n",
    "grad_func_unrolled = (grad(composition_func))\n",
    "unrolled_grads = grad_func_unrolled(all_params)\n",
    "print(composition_func(all_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c85a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2483.4785986185616\n"
     ]
    }
   ],
   "source": [
    "def composition_func(params):\n",
    "    # one of the implicit implementations, inherits the forward pass from slds_inference_implicit\n",
    "    a,b = SLDS_Inference.slds_inference_itersolve_uncapped(*params, initializer) \n",
    "    \n",
    "    # computes KL(q(z,k) || p(z,k))\n",
    "    c = SLDS_Inference.slds_kl(*params, a, b, 0.) \n",
    "    return sum(tree_map(lambda x: x.sum(), a)) + c\n",
    "\n",
    "grad_func_implicit = jit(grad(composition_func))\n",
    "implicit_grads = grad_func_implicit(all_params)\n",
    "print(composition_func(all_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3fe558",
   "metadata": {},
   "source": [
    "Numerical impressions accrue, but we see below the gradients are very similar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "850397eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((Array(0.00013658, dtype=float32), Array(0.00029361, dtype=float32)),\n",
       " (Array(0.00734411, dtype=float64),\n",
       "  Array(0.0034201, dtype=float64),\n",
       "  Array(0.00395355, dtype=float64),\n",
       "  Array(0.00342012, dtype=float64),\n",
       "  Array(0.00734407, dtype=float64),\n",
       "  Array(7.05213665e-13, dtype=float64)),\n",
       " (Array(3.1836066e-08, dtype=float64), Array(1.60530376e-07, dtype=float64)),\n",
       " Array(0., dtype=float64),\n",
       " Array(5.48519563e-15, dtype=float64),\n",
       " Array(1.68606448e-13, dtype=float64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each parameter, the mean absolute different in gradient values\n",
    "tree_map(lambda x,y: jnp.abs(jnp.mean(x-y)), unrolled_grads, implicit_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1347bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
